# -*- coding: utf-8 -*-
"""MPR SEM6.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1RbboIXRcYSAIi4UrfU585pYFOS3wDkBF
"""

import pandas as pd
df = pd.read_csv("PMC Hospital Infrastructure.csv")  # Change filename accordingly
df.head()

# Check shape (rows, columns)
print(f"Dataset contains {df.shape[0]} rows and {df.shape[1]} columns.")

# Check column data types
print(f"\nColumn Data Types:\n{df.dtypes}")

# Check missing values
print(f"\nMissing Values:\n{df.isnull().sum()}")

"""# **Data Cleaning**

"""

# Drop 'Ward No.' column since it has all missing values
df.drop(columns=['Ward No.'], inplace=True)

# Convert 'N.A.' and other non-numeric values to NaN
df['Average Monthly Patient Footfall'] = pd.to_numeric(df['Average Monthly Patient Footfall'], errors='coerce')

# Fill missing values using direct assignment
df.loc[:, 'Zone Name'] = df['Zone Name'].fillna(df['Zone Name'].mode()[0])  # Fill with most frequent value
df.loc[:, 'Zone No.'] = df['Zone No.'].fillna(df['Zone No.'].median())  # Fill with median value
df.loc[:, 'Ward Name'] = df['Ward Name'].fillna(df['Ward Name'].mode()[0])
df.loc[:, 'Average Monthly Patient Footfall'] = df['Average Monthly Patient Footfall'].fillna(df['Average Monthly Patient Footfall'].median())

# Convert numerical columns from object to int/float
df.loc[:, 'Number of Doctors / Physicians'] = pd.to_numeric(df['Number of Doctors / Physicians'], errors='coerce')
df.loc[:, 'Number of Nurses'] = pd.to_numeric(df['Number of Nurses'], errors='coerce')
df.loc[:, 'Number of Midwives Professional '] = pd.to_numeric(df['Number of Midwives Professional '], errors='coerce')
df.loc[:, 'Average Monthly Patient Footfall'] = pd.to_numeric(df['Average Monthly Patient Footfall'], errors='coerce')

# Rename columns to remove extra spaces
df.rename(columns=lambda x: x.strip(), inplace=True)

# Recheck missing values after transformations
print("\nMissing Values After Cleaning:")
print(df.isnull().sum())

df.dropna(subset=['Number of Doctors / Physicians', 'Number of Nurses', 'Number of Midwives Professional'], inplace=True)

print(df.columns)

df['Number of Midwives Professional'] = pd.to_numeric(df.get('Number of Midwives Professional'), errors='coerce')

# Recheck missing values after transformations
print("\nMissing Values After Cleaning:")
print(df.isnull().sum())

# Check final column data types
print("\nUpdated Column Data Types:")
print(df.dtypes)

# Convert numerical columns from object to int/float
numeric_columns = [
    'Number of Beds in Emergency Wards',
    'Number of Doctors / Physicians',
    'Number of Nurses',
    'Number of Midwives Professional',
    'Average Monthly Patient Footfall',
    'Count of Ambulance'
]

for col in numeric_columns:
    if col in df.columns:
        df[col] = df[col].astype(str).str.strip()  # Remove extra spaces
        df[col] = pd.to_numeric(df[col], errors='coerce')  # Convert to numeric

# Check final column data types again
print("\nUpdated Column Data Types:")
print(df.dtypes)

# Check columns that are still of object data type
object_columns = df.select_dtypes(include=['object']).columns
print("\nColumns still of object type:")
print(object_columns)

# Check the first few rows of each column with object data type
for col in object_columns:
    print(f"\nInspecting column: {col}")
    print(df[col].unique())  # Inspect unique values for odd characters or patterns

# Verify columns before dropping
columns_to_drop = ['City Name','Zone Name', 'Ward Name', 'Facility Name']
missing_columns = [col for col in columns_to_drop if col not in df.columns]

if not missing_columns:
    # Drop the columns if they exist
    df = df.drop(columns=columns_to_drop)
else:
    print(f"These columns are missing from the DataFrame: {missing_columns}")

"""We have dropped 3 colums - ZONE NAME , WARD NAME ,FACILITY NAME"""

# Check final column data types again
print("\nUpdated Column Data Types:")
print(df.dtypes)

"""REST OF THE COLUMNS WHICH ARE STILL OF OBJECT Data Type will apply encoding of different type on them"""

print("Columns in dataset:\n", df.columns)
print("\nMissing values after cleaning:\n",df.isnull().sum())

# Filling missing numerical values with median
numerical_cols = [
    'Number of Beds in Emergency Wards',
    'Number of Doctors / Physicians',
    'Number of Nurses',
    'Number of Midwives Professional',
    'Count of Ambulance'
]

for col in numerical_cols:
    if col in df.columns:
        df[col] = df[col].fillna(df[col].median())  # Safe assignment without warning

# Check missing values again
print("\nMissing values after filling:\n", df.isnull().sum())

for col in numerical_cols:
    if col in df.columns:
        df[col] = pd.to_numeric(df[col], errors='coerce')  # Ensure they are numeric

df.to_csv("cleaned_data.csv", index=False)

"""## **EDA ANALYSIS**

"""

# Import necessary libraries
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd

# Display summary statistics
print(df.describe())

# Check for missing values after cleaning
print("\nMissing values after cleaning:")
print(df.isnull().sum())

# Plot distributions of numerical features
df.hist(figsize=(12, 8), bins=30, edgecolor="black")
plt.suptitle("Feature Distributions", fontsize=16)
plt.show()

# Cell 5: Boxplot for outlier detection
plt.figure(figsize=(12, 6))
sns.boxplot(data=df, orient="h")
plt.title("Boxplot for Outlier Detection")
plt.show()

# Cell 6: Correlation heatmap for numerical columns
numeric_df = df.select_dtypes(include=['number'])  # Select only numerical columns
sns.heatmap(numeric_df.corr(), annot=True, cmap="coolwarm", fmt=".2f")
plt.title("Feature Correlation Heatmap")
plt.show()

# Cell 7: Countplot for categorical columns
categorical_cols = df.select_dtypes(include=["object"]).columns
for col in categorical_cols:
    plt.figure(figsize=(8, 4))
    sns.countplot(data=df, x=col, palette="viridis")
    plt.xticks(rotation=45)
    plt.title(f"Distribution of {col}")
    plt.show()

# Cell 8: Check the distribution of the target variable (if it's numerical)
sns.histplot(df['Average Monthly Patient Footfall'], kde=True)
plt.title('Distribution of Average Monthly Patient Footfall')
plt.show()

df = pd.read_csv("cleaned_data.csv")  # If you saved it after cleaning but before encoding

"""# **DATA PRE-PROCESSING**

Handling Categorical Variables
"""

# Import necessary libraries
import pandas as pd
from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler

# Drop the City Name column (if not already dropped)
df = df.drop(columns=['City Name'], errors='ignore')

# Identify categorical columns (excluding the ones you dropped earlier)
categorical_cols = df.select_dtypes(include=['object']).columns
print("Categorical Columns:", categorical_cols)

# One-Hot Encoding for columns with more than 2 categories
one_hot_cols = ['Type  (Hospital / Nursing Home / Lab)', 'Class : (Public / Private)']  # You can add other multi-category columns here

# Apply One-Hot Encoding using pandas' get_dummies (removes the first category to avoid multicollinearity)
df = pd.get_dummies(df, columns=one_hot_cols, drop_first=True)

# Label Encoding for binary categorical columns
binary_cols = ['Pharmacy Available : Yes/No', 'Ambulance Service Available']

label_encoders = {}
for col in binary_cols:
    le = LabelEncoder()
    df[col] = le.fit_transform(df[col])  # Convert 'Yes'/'No' to 1/0
    label_encoders[col] = le  # Store the encoder for future use

print("\nDataset after encoding:")
print(df.head())

# Convert True/False to 1/0 for the One-Hot Encoded columns
one_hot_encoded_cols = [col for col in df.columns if 'Type  (Hospital / Nursing Home / Lab)' in col]

for col in one_hot_encoded_cols:
    df[col] = df[col].astype(int)

# Check the DataFrame again
print(df.head())

# Show all column names, first few rows, and data types
print(df.columns)  # Show all column names
print(df.head())   # Show first few rows of the dataset
print(df.dtypes)   # Check data types of each column

# Feature Scaling for numerical columns
scaler = StandardScaler()

# Select numerical columns for scaling
num_cols = [
    'Zone No.', 'Number of Beds in Emergency Wards', 'Number of Beds in facility type',
    'Number of Doctors / Physicians', 'Number of Nurses', 'Number of Midwives Professional',
    'Count of Ambulance', 'Average Monthly Patient Footfall'
]

df[num_cols] = scaler.fit_transform(df[num_cols])

print("Feature scaling done ✅")

"""Since we have numerical features like Number of Beds, Doctors, etc., we should apply Min-Max Scaling or Standardization.

# **Train-Test Split**
"""

from sklearn.model_selection import train_test_split

X = df.drop(columns=['Average Monthly Patient Footfall'])  # Features
y = df['Average Monthly Patient Footfall']  # Target variable

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print("Train-Test Split Done ✅")
print("Training Set:", X_train.shape, y_train.shape)
print("Test Set:", X_test.shape, y_test.shape)

"""# **Implement MLR in TensorFlow**"""

#Import Required Libraries
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import numpy as np
import pandas as pd

print(X_train.columns)
print(X_test.columns)

# Drop unnecessary columns (if any) from X_train and X_test (e.g., City Name, Facility Name, Ward Name)
cols_to_drop = ['City Name', 'Facility Name', 'Ward Name']  # Already removed earlier
X_train = X_train.drop(columns=cols_to_drop, errors='ignore')
X_test = X_test.drop(columns=cols_to_drop, errors='ignore')

# Ensure no non-numeric columns remain
print(X_train.dtypes)  # Check if any non-numeric columns remain

# Convert data to TensorFlow tensors
X_train_tensor = tf.convert_to_tensor(X_train, dtype=tf.float32)
X_test_tensor = tf.convert_to_tensor(X_test, dtype=tf.float32)
y_train_tensor = tf.convert_to_tensor(y_train, dtype=tf.float32)
y_test_tensor = tf.convert_to_tensor(y_test, dtype=tf.float32)

# Define a Linear Regression model (Multiple Linear Regression)
model = keras.Sequential([
    layers.Dense(units=1, input_shape=(X_train.shape[1],))  # Single layer with no activation, i.e., linear regression
])

# Compile the model (using Mean Squared Error for loss, as it is a regression task)
model.compile(optimizer='adam', loss='mse', metrics=['mae'])

# Train the model
history = model.fit(X_train_tensor, y_train_tensor, epochs=100, validation_data=(X_test_tensor, y_test_tensor))

# Evaluate the model
test_loss, test_mae = model.evaluate(X_test_tensor, y_test_tensor)
print(f"Test Loss (MSE): {test_loss}, Test MAE: {test_mae}")

# Make predictions
y_pred = model.predict(X_test_tensor)

# Convert predictions to 1D arrays for metric calculations
y_pred_flat = y_pred.flatten()
y_test_flat = y_test_tensor.numpy().flatten()

# Calculate RMSE
rmse = np.sqrt(mean_squared_error(y_test_flat, y_pred_flat))
print("Root Mean Squared Error (RMSE):", rmse)

# Calculate R2 Score
r2 = r2_score(y_test_flat, y_pred_flat)
print("R² Score:", r2)

# Custom Accuracy: Percentage of predictions within 10% of actual values
custom_accuracy = np.mean(np.abs((y_test_flat - y_pred_flat) / y_test_flat))
print("Custom Accuracy within 10% tolerance:", custom_accuracy * 100, "%")

"""# New section"""

import matplotlib.pyplot as plt
import numpy as np

plt.scatter(y_test, y_pred, label='Predictions')
plt.xlabel('Actual Values')
plt.ylabel('Predicted Values')
plt.title('Actual vs Predicted')

# Add line y = x
min_val = min(y_test.min(), y_pred.min())
max_val = max(y_test.max(), y_pred.max())
plt.plot([min_val, max_val], [min_val, max_val], color='red', linestyle='--', label='Perfect Prediction (y = x)')

plt.legend()
plt.grid(True)
plt.show()

# Compare predictions with actual values
import matplotlib.pyplot as plt

plt.scatter(y_test, y_pred)
plt.xlabel('Actual Values')
plt.ylabel('Predicted Values')
plt.title('Actual vs Predicted')
plt.show()